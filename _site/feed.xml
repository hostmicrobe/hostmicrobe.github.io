<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">Home</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml" />
<link rel="alternate" type="text/html" href="http://localhost:4000" />
<updated>2018-01-04T22:02:02-05:00</updated>
<id>http://localhost:4000/</id>
<author>
  <name>Beiting</name>
  <uri>http://localhost:4000/</uri>
  <email>danielbeiting@gmail.com</email>
</author>


<entry>
  <title type="html"><![CDATA[Cloud computing for metagenomics - 4hr workshop]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/microbiome/cloudComputing_workshop/" />
  <id>http://localhost:4000/microbiome/cloudComputing_workshop</id>
  <updated>2017-11-06T00:00:00-00:00</updated>
  <published>2017-11-06T00:00:00-05:00</published>
  
  <author>
    <name>Beiting</name>
    <uri>http://localhost:4000</uri>
    <email>danielbeiting@gmail.com</email>
  </author>
  <content type="html">
    &lt;section id=&quot;table-of-contents&quot; class=&quot;toc&quot;&gt;
  &lt;header&gt;
    &lt;h3&gt;&lt;i class=&quot;fa fa-book&quot;&gt;&lt;/i&gt; Table of Contents&lt;/h3&gt;
  &lt;/header&gt;
&lt;div id=&quot;drawer&quot;&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#before-starting&quot; id=&quot;markdown-toc-before-starting&quot;&gt;Before starting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#launch-the-google-cloud-instance&quot; id=&quot;markdown-toc-launch-the-google-cloud-instance&quot;&gt;Launch the Google Cloud instance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#installing-the-sunbeam-metagenomics-pipeline&quot; id=&quot;markdown-toc-installing-the-sunbeam-metagenomics-pipeline&quot;&gt;Installing the Sunbeam metagenomics pipeline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#test-drive&quot; id=&quot;markdown-toc-test-drive&quot;&gt;test drive&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#connect-to-glcoud-instance&quot; id=&quot;markdown-toc-connect-to-glcoud-instance&quot;&gt;connect to glcoud instance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#transfer-data-to-glcoud&quot; id=&quot;markdown-toc-transfer-data-to-glcoud&quot;&gt;transfer data to glcoud&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#fetch-your-reference-files&quot; id=&quot;markdown-toc-fetch-your-reference-files&quot;&gt;fetch your reference files&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#run-sunbeam&quot; id=&quot;markdown-toc-run-sunbeam&quot;&gt;Run Sunbeam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#interpreting-your-results&quot; id=&quot;markdown-toc-interpreting-your-results&quot;&gt;Interpreting your results&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/section&gt;
&lt;!-- /#table-of-contents --&gt;

&lt;h2 id=&quot;before-starting&quot;&gt;Before starting&lt;/h2&gt;
&lt;p&gt;Around the time my lab was starting to experiment with using Dockerized tools and cloud compute resources for analzying metagenomic data – which culminated in a two part blog post &lt;a href=&quot;http://hostmicrobe.org/microbiome/cloudComputing_part1/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://hostmicrobe.org/microbiome/cloudComputing_part2/&quot;&gt;here&lt;/a&gt; – &lt;a href=&quot;https://microbiome.research.chop.edu/our-team/kyle-bittinger.html&quot;&gt;Kyle Bittinger&lt;/a&gt; and his group at the PennCHOP Microbiome Center were finishing up their work developing a Snakemake-based pipeline for metagenomics.  With our annual microbiome symposium quickly approaching, Kyle and I decided to join forces to host a 1/2 day workshop that would combine these elements.&lt;/p&gt;

&lt;p&gt;The material below is intended to walk you through this workshop, and provide a general web-based lesson plan for how one might conduct such a workshop.&lt;/p&gt;

&lt;p&gt;To participate in this workshop, you’ll only need a few things:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a laptop computer&lt;/li&gt;
  &lt;li&gt;an internet connection&lt;/li&gt;
  &lt;li&gt;a google account (free)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.google.com&quot;&gt;a google cloud account&lt;/a&gt; (free sign-up and $300 credit)&lt;/li&gt;
  &lt;li&gt;example data that you can &lt;a href=&quot;https://upenn.box.com/shared/static/q7tje8tzs2y73ns46qvrjm6ehuz7j0sc.zip&quot;&gt;download here&lt;/a&gt;. This dataset will be explained in more detail during the workshop, but is also described &lt;a href=&quot;http://hostmicrobe.org/microbiome/cloudComputing_part2/&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;launch-the-google-cloud-instance&quot;&gt;Launch the Google Cloud instance&lt;/h2&gt;

&lt;p&gt;We’ll begin the workshop with a demonstration of how to launch your first Google Cloud instance.  We’ll then connect to this instance via the gcloud SSH button.  Once connected, we’re all using exactly the same type of computer with the same operating system, regardless of your local machine and OS.&lt;/p&gt;

&lt;h2 id=&quot;installing-the-sunbeam-metagenomics-pipeline&quot;&gt;Installing the Sunbeam metagenomics pipeline&lt;/h2&gt;

&lt;p&gt;After launching, we need to install some system programs on the computer.  For this, we’ll use the &lt;code class=&quot;highlighter-rouge&quot;&gt;apt-get&lt;/code&gt; utility provided with the operating system.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get install unzip xvfb xdotool libxrender1 libxi6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We’ll download the &lt;a href=&quot;https://github.com/eclarke/sunbeam&quot;&gt;Sunbeam software&lt;/a&gt; from GitHub, where it is distributed.  &lt;strong&gt;Again, this is a new pipeline from Kyle’s group, and he’ll spend substantial time during the workshop talking about what is happening under the hood as we run Sunbeam.&lt;/strong&gt;  We’ll also briefly discuss why this pipeline was created with &lt;a href=&quot;http://snakemake.readthedocs.io/en/stable/&quot;&gt;Snakemake&lt;/a&gt; and uses a &lt;a href=&quot;https://conda.io/docs/&quot;&gt;Conda environment&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://github.com/eclarke/sunbeam/archive/master.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After the software is downloaded successfully, you’ll have a new file called &lt;code class=&quot;highlighter-rouge&quot;&gt;master.zip&lt;/code&gt; in your home directory.  You can verify this with the &lt;code class=&quot;highlighter-rouge&quot;&gt;ls&lt;/code&gt; command. Now that the file is downloaded, we’ll decompress
the file with &lt;code class=&quot;highlighter-rouge&quot;&gt;unzip&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;unzip master.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We move into the software directory, where the installation scripts are located.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;sunbeam-master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now, we’re ready to actually install the Sunbeam analysis pipeline. Sunbeam provides a script for this purpose.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./install.sh
./install_igv.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The pipeline uses a system called Conda to manage all the bioinformatics analysis programs. This system works by storing all the programs inside your home directory, so that we can use special versions of programs just for this pipeline. We’ll tell the computer where to find the Conda system.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;export PATH=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/miniconda3/bin:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\$&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;PATH&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.bashrc
&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To actually use Sunbeam, we’ll “turn on” the bioinformatics software.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;activate sunbeam
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is the command you’ll want to remember for future sessions.  Each time you log into your cloud instance, you’ll need to activate the pipeline with &lt;code class=&quot;highlighter-rouge&quot;&gt;source activate sunbeam&lt;/code&gt;.  Upon activation, you should see that your command prompt begins with “(sunbeam)”.  Anytime you want to exit out of sunbeam, simply type &lt;code class=&quot;highlighter-rouge&quot;&gt;source deactivate sunbeam&lt;/code&gt; and hit return.&lt;/p&gt;

&lt;h2 id=&quot;test-drive&quot;&gt;test drive&lt;/h2&gt;

&lt;p&gt;Now that our software is installed and activated, we’ll run the tests included with Sunbeam to make sure everything is OK.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bash tests/test.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As the tests are running, you should see messages scrolling by on your screen. This is a preview of what you might see when the actual pipeline is running, so we’ll devote some time in our session to understanding the messages.&lt;/p&gt;

&lt;p&gt;Our next step is to download our data files and get moving with some real data analysis!&lt;/p&gt;

&lt;h2 id=&quot;connect-to-glcoud-instance&quot;&gt;connect to glcoud instance&lt;/h2&gt;
&lt;p&gt;Although the ssh terminal available right on your instance is very convenient, it does not establish a connection between our local computer and the cloud instance (which we must do in order to move files back and forth).  In order to do that, we’ll want to connect to our instance from the &lt;a href=&quot;https://en.wikipedia.org/wiki/Terminal_(macOS)&quot;&gt;terminal app&lt;/a&gt; on our local computer.  Go ahead and launch your Terminal app.  Before we do anything else, let’s execute a command in the terminal that will allow us to see hidden files in our directory.  We need access to a few of these hidden files for the purposes of this tutorial.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;defaults write com.apple.finder AppleShowAllFiles &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#then restart the finder to see these changes&lt;/span&gt;
killall Finder
&lt;span class=&quot;c&quot;&gt;#after this tutorial you can hide these files again by replacing 'true' with 'false'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now install the google SDK.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl https://sdk.cloud.google.com | bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I my experience, if you encounter any issues with this entire tutorial, it will be with getting the SDK installed and connecting to your instance. For example, you may notice that the installation fails with the following error&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ERROR: Failed to fetch component listing from server. Check your network settings and try again
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This error has to do with the the IPv6 settings on your computer preventing you from being able to connect with a google server to download the SDK command line tools&lt;/p&gt;

&lt;p&gt;If you encounter this error, this fix is simple.  Begin by temporarily turning off IPv6 support for either Wi-Fi or Ethernet, depending on which one you are using to connect to the internet.  If you’re using a Wi-Fi connection, then you would turn-off with:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;networksetup &lt;span class=&quot;nt&quot;&gt;-setv6off&lt;/span&gt; Wi-Fi &lt;span class=&quot;c&quot;&gt;#if you're using ethernet, replace 'Wi-Fi' with 'Ethernet' in this line&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now reattempt the installation as you did above&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl https://sdk.cloud.google.com | bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once you have Google Cloud SDK installed, &lt;em&gt;be sure to turn the IPv6 back on&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;networksetup &lt;span class=&quot;nt&quot;&gt;-setv6automatic&lt;/span&gt; Wi-Fi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we’ll connect to the instance from within our Terminal.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gcloud compute ssh instance-1 &lt;span class=&quot;c&quot;&gt;#if your instance is not called 'instance-1', be sure to modify this line accordingly&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Be patient here, as this may take a moment to connect.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If the above command failed with an authentication error, it’s because this is the first time you’ve run SDK and it isn’t sure that you should have access to your google account from the terminal.  Take a moment to authenticate&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gcloud auth login
&lt;span class=&quot;c&quot;&gt;#this will open a browser window for you to select and sign-in to your google account&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#after doing this, return to your terminal window and you should be good to go&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#if this doesn't work, you may need to go though the gcloud initialization process by executing 'gcloud init'&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#either way, once you have authenticated your account you will need to reattempt connecting with 'gcloud compute ssh instance-1'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;transfer-data-to-glcoud&quot;&gt;transfer data to glcoud&lt;/h2&gt;

&lt;p&gt;In this part of the workshop you’ll learn all the point-and-click steps to connect to your gcloud instance via SFTP using the &lt;a href=&quot;https://filezilla-project.org/&quot;&gt;FileZilla program&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is important to keep our file system organized by project.  To do this, we’ll use FileZilla to create a new folder in your home directory called ‘deadmice’, which will be our project folder for today.  Open this folder (double click) and create a subfolder called ‘data_files’.  Your project folder can be named anything, but each project folder must have a ‘data_files’ subfolder where all raw data input files should be stored.&lt;/p&gt;

&lt;p&gt;With these folders in place, use FileZilla to drag-and-drop all the fastq files you downloaded for the workshop into the ‘data_files’ folder.&lt;/p&gt;

&lt;h2 id=&quot;fetch-your-reference-files&quot;&gt;fetch your reference files&lt;/h2&gt;

&lt;p&gt;We have bundled a number of commands for getting reference files into a shell script that you can download &lt;a href=&quot;http://hostmicrobe.github.io/myPapers/download_refdata.sh&quot;&gt;here&lt;/a&gt;.  We’ll discuss the content of this file during the workshop.&lt;/p&gt;

&lt;p&gt;Use FileZilla to drag-and-drop this shell script into your home directory on gcloud.&lt;/p&gt;

&lt;p&gt;Now run the shell script&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~
bash download_refdata.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;run-sunbeam&quot;&gt;Run Sunbeam&lt;/h2&gt;

&lt;p&gt;Run sunbeam (this will take about 1hr to complete)&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/sunbeam-master
snakemake &lt;span class=&quot;nt&quot;&gt;--configfile&lt;/span&gt; deadmice-config.yml &lt;span class=&quot;nt&quot;&gt;--cores&lt;/span&gt; 8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;interpreting-your-results&quot;&gt;Interpreting your results&lt;/h2&gt;

&lt;p&gt;Running Sunbeam will produce a third subdirectory for the output files (“sunbeam_output”).&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/microbiome/cloudComputing_workshop/&quot;&gt;Cloud computing for metagenomics - 4hr workshop&lt;/a&gt; was originally published by Beiting at &lt;a href=&quot;http://localhost:4000&quot;&gt;Home&lt;/a&gt; on November 06, 2017.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[Cloud computing for metagenomics - Part II]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/microbiome/cloudComputing_part2/" />
  <id>http://localhost:4000/microbiome/cloudComputing_part2</id>
  <updated>2017-09-19T00:00:00-00:00</updated>
  <published>2017-09-19T00:00:00-04:00</published>
  
  <author>
    <name>Beiting</name>
    <uri>http://localhost:4000</uri>
    <email>danielbeiting@gmail.com</email>
  </author>
  <content type="html">
    &lt;section id=&quot;table-of-contents&quot; class=&quot;toc&quot;&gt;
  &lt;header&gt;
    &lt;h3&gt;&lt;i class=&quot;fa fa-book&quot;&gt;&lt;/i&gt; Table of Contents&lt;/h3&gt;
  &lt;/header&gt;
&lt;div id=&quot;drawer&quot;&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#getting-started&quot; id=&quot;markdown-toc-getting-started&quot;&gt;Getting started&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#running-metaphlan2&quot; id=&quot;markdown-toc-running-metaphlan2&quot;&gt;Running MetaPhlAn2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#visualizing-your-results&quot; id=&quot;markdown-toc-visualizing-your-results&quot;&gt;Visualizing your results&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#automate-your-workflow&quot; id=&quot;markdown-toc-automate-your-workflow&quot;&gt;Automate your workflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/section&gt;
&lt;!-- /#table-of-contents --&gt;

&lt;h2 id=&quot;getting-started&quot;&gt;Getting started&lt;/h2&gt;
&lt;p&gt;We spent &lt;a href=&quot;http://hostmicrobe.org/microbiome/cloudComputing_part1/&quot;&gt;part I&lt;/a&gt; of this series going over each step involved in setting up a Google Cloud Instance, installing &lt;a href=&quot;https://www.docker.com/&quot;&gt;Docker&lt;/a&gt; on this instance, and then installing a suite of dockerized metagenomics tools via &lt;a href=&quot;https://github.com/IGS/Chiron&quot;&gt;Chiron&lt;/a&gt;.  If you haven’t read part I, please &lt;em&gt;stop reading&lt;/em&gt; and go back now.&lt;/p&gt;

&lt;p&gt;In this post, we actually get to put all those painstaking steps from Part 1 to good use by employing &lt;a href=&quot;http://hostmicrobe.github.io/myPapers/metaphlan2.pdf&quot;&gt;MetaPhlAn2&lt;/a&gt; to go from raw .fastq files to a table of microbial composition.  To get the most from this tutorial, you’ll need some ‘real’ data, and for that we’ll turn an unfortunate series of events that unfolded in the summer of 2015.  UPenn’s University Lab Animal Resources (ULAR) group, which oversees all veterinary care and support for research animals on campus, began to notice diarrhea in a few cages of immuno-compromised mice.  If you’re not familiar with mouse models for research, there a many genetically engineered mice that lack various immune system components.  The particular mice that fell ill are what we would call NSG and NSGS mice, strains that are effectively devoid of nearly all aspects of the immune system.  Such mice are ideal recipients for xenografts (i.e. human tumor grafts) and critical for understanding cancer biology and therpeutics, but they also pose a real challenge in terms of infection control.  You can probably guess where this is going.  Despite the strictest precautions, what started out as a few cages of sick mice quickly became an outbreak of diarrheal disease, eventually decimating the entire suite.&lt;/p&gt;

&lt;p&gt;After extenisve molecular and culture-based diagnostics turned up negative, we were asked whether microbiome profiling might be able to identify putative organisms associated with the outbreak.  Given that the causative agent could be bacterial, viral or something else entirely, we opted to carry out ‘shotgun’ metagenomic profiling of stool samples obtained from affected mice and controls.  To start this tutorial, you’ll want to download that data &lt;a href=&quot;https://www.dropbox.com/sh/kznl838218eozdk/AAA1DECGgb0SHBXLeEBjFsMEa?dl=0&quot;&gt;here&lt;/a&gt;.  A few things to take note of:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;there are 6 .fastq files total.  Download them all, and it doesn’t matter where you put them on your computer&lt;/li&gt;
  &lt;li&gt;Files have been subsampled to 1 million reads each using &lt;a href=&quot;https://github.com/lh3/seqtk&quot;&gt;seqtk&lt;/a&gt;, so that this tutorial moves more quickly&lt;/li&gt;
  &lt;li&gt;you’ll need about 2Gb of space on your harddrive to store these files&lt;/li&gt;
  &lt;li&gt;each file contains sequence reads from the stool of 1 mouse.&lt;/li&gt;
  &lt;li&gt;each file is gzip’d (ends in .gz).  This is a compression format.  &lt;em&gt;Do not&lt;/em&gt; unzip the files after you’ve downloaded them&lt;/li&gt;
  &lt;li&gt;There are 3 files from control mice and 3 from affected.  This will be obvious from the file names&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;The goal of this tutorial is to use cloud-based metagenomics to identify organisms associated with this devastating outbreak.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;running-metaphlan2&quot;&gt;Running MetaPhlAn2&lt;/h2&gt;
&lt;p&gt;Back in Part I of this series, you launched an interactive MetaPhlAn2 session and used the -l option to create a folder called &lt;em&gt;data&lt;/em&gt;.  You’ll want to make sure to fire up this interactive session again&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; ./Chiron/bin/phlan_interactive &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; ~/data
&lt;span class=&quot;c&quot;&gt;#the -l option tells the interactive to create a new folder in our home directory called 'data', and sets this folder as the default from which data will be read and to which outputs will be saved &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#This is where we'll put all our raw sequence data for analysis&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Using FileZilla, transfer these files from your computer to the &lt;em&gt;data&lt;/em&gt; folder on your cloud instance.  If your confused about how to do this, you may want to go back and watch &lt;a href=&quot;http://hostmicrobe.org/microbiome/cloudComputing_part1/#fire-up-your-cloud-computer&quot;&gt;my video&lt;/a&gt; on how to connect use and FTP client to transfer files to the cloud&lt;/p&gt;

&lt;p&gt;Now that you have everything in place, you need to naviagte the &lt;em&gt;output&lt;/em&gt; folder using within the MetaPhlAn interactive by using &lt;code class=&quot;highlighter-rouge&quot;&gt;cd output&lt;/code&gt;.  This is where all your files that were placed in the data folder will be available to you while your running an interactive program.&lt;/p&gt;

&lt;p&gt;let’s run MetaPhlAn2 on one sample using a single line of code.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;metaphlan2.py Control7_merged_trimmed.fastq.gz &lt;span class=&quot;nt&quot;&gt;--input_type&lt;/span&gt; fastq &lt;span class=&quot;nt&quot;&gt;--nproc&lt;/span&gt; 8 &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Control7_profile.txt
&lt;span class=&quot;c&quot;&gt;#the --nproc option lets us choose the number of processors we'd like to use for this job&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Once this is done running, take a look at the resulting output file that contains all the taxa identified in a sample  You can now modify the input and output to analyze each sample.  There’s a more efficient way to do this, using something called a shell script to automate the analysis of all your .fastq files.  We’ll come back to this idea at the end of the tutorial.&lt;/p&gt;

&lt;p&gt;Now let’s merge all 6 of the profile.txt output files to create a single analysis output file&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;merge_metaphlan_tables.py &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;_profile.txt &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; merged_abundance_table.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now you have a single file &lt;em&gt;merged_abundance_table.txt&lt;/em&gt; which contains a breakdown of all the taxa present in all of your samples.&lt;/p&gt;

&lt;h2 id=&quot;visualizing-your-results&quot;&gt;Visualizing your results&lt;/h2&gt;
&lt;p&gt;Now you’ll use &lt;a href=&quot;&quot;&gt;regular expressions&lt;/a&gt; to parse this file, and create a new file that only lists abundance for species&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-E&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;(s__)|(^ID)&quot;&lt;/span&gt; merged_abundance_table.txt | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;t__&quot;&lt;/span&gt; | sed &lt;span class=&quot;s1&quot;&gt;'s/^.*s__//g'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; merged_abundance_table_species.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You’re now ready to use MetaPhlAn to create a heatmap of these species&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;hclust2.py &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; merged_abundance_table_species.txt &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; abundance_heatmap_species.png &lt;span class=&quot;nt&quot;&gt;--ftop&lt;/span&gt; 25 &lt;span class=&quot;nt&quot;&gt;--f_dist_f&lt;/span&gt; braycurtis &lt;span class=&quot;nt&quot;&gt;--s_dist_f&lt;/span&gt; braycurtis &lt;span class=&quot;nt&quot;&gt;--cell_aspect_ratio&lt;/span&gt; 0.5 &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--flabel_size&lt;/span&gt; 6 &lt;span class=&quot;nt&quot;&gt;--slabel_size&lt;/span&gt; 6 &lt;span class=&quot;nt&quot;&gt;--max_flabel_len&lt;/span&gt; 100 &lt;span class=&quot;nt&quot;&gt;--max_slabel_len&lt;/span&gt; 100 &lt;span class=&quot;nt&quot;&gt;--minv&lt;/span&gt; 0.1 &lt;span class=&quot;nt&quot;&gt;--dpi&lt;/span&gt; 300&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;http://hostmicrobe.github.io/images/abundance_heatmap_species.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While heatmaps are a great way to visualize changes in the abundance of taxa across treatment groups, they don’t preserve the taxonomic relationship between taxa.  For that, we’ll use another tool from the Huttenhower lab, &lt;a href=&quot;https://huttenhower.sph.harvard.edu/graphlan&quot;&gt;GraPhlAn&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;export2graphlan.py &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; merged_abundance_table.txt &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; tree.txt &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; annot1.txt &lt;span class=&quot;nt&quot;&gt;--skip_rows&lt;/span&gt; 1
graphlan_annotate.py &lt;span class=&quot;nt&quot;&gt;--annot&lt;/span&gt; annot1.txt tree.txt tree1.xml
graphlan.py tree1.xml tree1.png &lt;span class=&quot;nt&quot;&gt;--dpi&lt;/span&gt; 150&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;http://hostmicrobe.github.io/images/tree1.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Let’s clean the taxonomy by removing taxon, &lt;em&gt;_noname&lt;/em&gt;, and &lt;em&gt;_unclassified&lt;/em&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;t__&quot;&lt;/span&gt; merged_abundance_table.txt | sed &lt;span class=&quot;s1&quot;&gt;'s/_noname//g'&lt;/span&gt; | sed &lt;span class=&quot;s1&quot;&gt;'s/_unclassified//g'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; merged_abundance_table_clean.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now redo the graphic, this time with the clean taxonomy&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;export2graphlan.py &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; merged_abundance_table_clean.txt &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; tree.txt &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; annot1.txt &lt;span class=&quot;nt&quot;&gt;--skip_rows&lt;/span&gt; 1
graphlan_annotate.py &lt;span class=&quot;nt&quot;&gt;--annot&lt;/span&gt; annot1.txt tree.txt tree_clean1.xml
graphlan.py tree_clean1.xml tree_clean1.png &lt;span class=&quot;nt&quot;&gt;--dpi&lt;/span&gt; 150&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;http://hostmicrobe.github.io/images/tree_clean1.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;redo the graphic again, this time with annotations&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;export2graphlan.py &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; merged_abundance_table_clean.txt &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; tree.txt &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; annot2.txt &lt;span class=&quot;nt&quot;&gt;--skip_rows&lt;/span&gt; 1 &lt;span class=&quot;nt&quot;&gt;--most_abundant&lt;/span&gt; 50 &lt;span class=&quot;nt&quot;&gt;--annotations&lt;/span&gt; 2,3,4,5,6 &lt;span class=&quot;nt&quot;&gt;--external_annotations&lt;/span&gt; 7 &lt;span class=&quot;nt&quot;&gt;--title&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;MetaPhlAn2 taxonomic results&quot;&lt;/span&gt;
graphlan_annotate.py &lt;span class=&quot;nt&quot;&gt;--annot&lt;/span&gt; annot2.txt tree.txt tree_clean2.xml
graphlan.py tree_clean2.xml tree_clean2.png &lt;span class=&quot;nt&quot;&gt;--dpi&lt;/span&gt; 150&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;http://hostmicrobe.github.io/images/tree_clean2.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;plot the graphic once more, this time spread out 360 degrees&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;total_plotted_degrees&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;330&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; annot3.txt
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;start_rotation&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;270&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; annot3.txt
&lt;span class=&quot;nv&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'#0000FF'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'#FFA500'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'#888888'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'#FF0000'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'#006400'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'#800080'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1
&lt;span class=&quot;nv&quot;&gt;OLDIFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$IFS&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;IFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;$'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;i &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;_profile.txt&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
    &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; | cut &lt;span class=&quot;nt&quot;&gt;-f2&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'-'&lt;/span&gt; | rev | cut &lt;span class=&quot;nt&quot;&gt;-f2-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'_'&lt;/span&gt; | tr &lt;span class=&quot;s1&quot;&gt;'_'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;' '&lt;/span&gt; | rev&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ring_label&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; annot3.txt
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ring_label_color&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[n-1]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; annot3.txt
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ring_internal_separator_thickness&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;0.25&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; annot3.txt

    &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;j &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;s__ | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; t__&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
        &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; | cut &lt;span class=&quot;nt&quot;&gt;-f1&lt;/span&gt; | rev | cut &lt;span class=&quot;nt&quot;&gt;-f1&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'|'&lt;/span&gt; | rev | sed &lt;span class=&quot;s1&quot;&gt;'s/_noname//g'&lt;/span&gt; | sed &lt;span class=&quot;s1&quot;&gt;'s/_unclassified//g'&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; | cut &lt;span class=&quot;nt&quot;&gt;-f2&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scale=4; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/100&quot;&lt;/span&gt; | bc&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ring_color&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[n-1]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; annot3.txt
        &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ring_alpha&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; annot3.txt
    &lt;span class=&quot;k&quot;&gt;done

    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;let &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;n+1
&lt;span class=&quot;k&quot;&gt;done

&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;IFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OLDIFS&lt;/span&gt;

graphlan_annotate.py &lt;span class=&quot;nt&quot;&gt;--annot&lt;/span&gt; annot3.txt tree_clean2.xml tree_clean3.xml
graphlan.py tree_clean3.xml tree_clean3.png &lt;span class=&quot;nt&quot;&gt;--dpi&lt;/span&gt; 150&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;http://hostmicrobe.github.io/images/tree_clean3.png&quot; alt=&quot;Alt text&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;automate-your-workflow&quot;&gt;Automate your workflow&lt;/h2&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/microbiome/cloudComputing_part2/&quot;&gt;Cloud computing for metagenomics - Part II&lt;/a&gt; was originally published by Beiting at &lt;a href=&quot;http://localhost:4000&quot;&gt;Home&lt;/a&gt; on September 19, 2017.&lt;/p&gt;
  </content>
</entry>


<entry>
  <title type="html"><![CDATA[Cloud computing for metagenomics - Part I]]></title>
  <link rel="alternate" type="text/html" href="http://localhost:4000/microbiome/cloudComputing_part1/" />
  <id>http://localhost:4000/microbiome/cloudComputing_part1</id>
  <updated>2017-07-14T00:00:00-00:00</updated>
  <published>2017-07-14T00:00:00-04:00</published>
  
  <author>
    <name>Beiting</name>
    <uri>http://localhost:4000</uri>
    <email>danielbeiting@gmail.com</email>
  </author>
  <content type="html">
    &lt;section id=&quot;table-of-contents&quot; class=&quot;toc&quot;&gt;
  &lt;header&gt;
    &lt;h3&gt;&lt;i class=&quot;fa fa-book&quot;&gt;&lt;/i&gt; Table of Contents&lt;/h3&gt;
  &lt;/header&gt;
&lt;div id=&quot;drawer&quot;&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#prelude&quot; id=&quot;markdown-toc-prelude&quot;&gt;Prelude&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-use-the-cloud&quot; id=&quot;markdown-toc-why-use-the-cloud&quot;&gt;Why use the cloud?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#fire-up-your-cloud-computer&quot; id=&quot;markdown-toc-fire-up-your-cloud-computer&quot;&gt;Fire up your cloud computer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#install-your-programs&quot; id=&quot;markdown-toc-install-your-programs&quot;&gt;Install your programs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#connect-to-your-instance&quot; id=&quot;markdown-toc-connect-to-your-instance&quot;&gt;Connect to your instance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#launch-an-interactive-session-with-chiron&quot; id=&quot;markdown-toc-launch-an-interactive-session-with-chiron&quot;&gt;Launch an interactive session with Chiron&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rinse-and-repeat&quot; id=&quot;markdown-toc-rinse-and-repeat&quot;&gt;Rinse and repeat&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/section&gt;
&lt;!-- /#table-of-contents --&gt;

&lt;h2 id=&quot;prelude&quot;&gt;Prelude&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer: This is my first blog post.&lt;/strong&gt;  That’s right, I’m a complete rookie at this.  Why now?  Well, since starting my faculty position four years ago and working to help build and direct the Center for Host-Microbial Interactions, I increasingly find myself involved in various collaborations or projects where I’m learning something I find really interesting and that I think would be useful to share with either my lab or with the broader scientific community, but which doesn’t easily translate into a traditional publication.  Basically, I’m learning some cool stuff, and it’s not always evident in my publications, so here we are.&lt;/p&gt;

&lt;p&gt;Case-in-point, I recently attended this &lt;a href=&quot;http://www.igs.umaryland.edu/topics/microbiome-cloud/&quot;&gt;Microbiome Analysis in the Cloud&lt;/a&gt;, held at the Institute for Genome Sciences at the University of Baltimore.  The two-day workshop had a lot of high points, including excellent planning and preparation on the part of the organizers, a highly skilled staff that worked the room to help troubleshoot, and a program that covered a lot of ground.  While that latter point was explicitly stated as a goal of the workshop, it means that I left the workshop feeling I wouldn’t be able to work through a full dataset on my own.  Now that I’ve had a chance to review the workshop materials, I feel a bit more comfortable and want to put down my workflow in this blog post.  Expect updates in the coming months as I marinate on this.&lt;/p&gt;

&lt;p&gt;I also want to acknowledge &lt;a href=&quot;https://github.com/jorvis&quot;&gt;Joshua Orvis&lt;/a&gt;, a bioinformatician at IGS and one of the workshop instructors.  Without his one-on-one help and his development of Chiron, this tutorial wouldn’t be possible.&lt;/p&gt;

&lt;h2 id=&quot;why-use-the-cloud&quot;&gt;Why use the cloud?&lt;/h2&gt;
&lt;p&gt;I’m not here to sell you on the idea of cloud computing.  In fact, maybe you should ignore all the buzz about ‘the cloud’.  After all, you accrue charges as your cloud instance runs.  As a consequence, failure to shut down a instance could result in some hefty charges if it slips your mind.  Some people cite that it’s a nussiance to move all your data to the cloud to begin working, only to then have to pull your results off the cloud before you shut it down.  But the same data gymnastics come into play when you use any remote computing resource.  Similarly, folks will often cite the problem that all programs and dependencies needed to carry out your work will have to be installed by you before your cloud instance is useful.  The arrival of &lt;a href=&quot;https://www.docker.com/&quot;&gt;Docker&lt;/a&gt; has largely made this a non-issue, in my opinion.  Yes, I’m aware that Docker is viewed with trepidation by some in the bioinformatics community (see &lt;a href=&quot;http://homolog.us/blogs/blog/2015/09/22/is-docker-for-suckers/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;http://lh3.github.io/2015/04/25/a-few-hours-with-docker/&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4586803/&quot;&gt;here&lt;/a&gt;), but it seems to me that Docker and cloud computing make good bed fellows.&lt;/p&gt;

&lt;p&gt;Still reluctant to dive in?  Well, an alternative to using cloud computing resources is to simply invest in your own compute cluster or leverage compute resources at your institution.  I have to say, both of these alternatives have some non-trivial downsides as well.  Running your own in-house compute cluster gives you tons of control, but with great power comes great responsibility, including that you’ll have to maintain it, which requries sysadmin skills.  Acquiring your fancy new computer will also take a serious chunk of change (think 10K or more), and the hardware quickly becomes outdated.  My university has &lt;a href=&quot;https://hpcwiki.genomics.upenn.edu/index.php/HPC:Main_Page&quot;&gt;a pretty awesome compute cluster&lt;/a&gt;, but if your favorite program isn’t available, you likely won’t have the access priveldges to install it yourself and it can take some time for the powers-that-be to get it installed.  We also experience frequent interruptions and server downtime on our university cluster.  Here’s the bottom line: just like any other resource, cloud computing has its pros and cons, and should be thought of not as the &lt;em&gt;only&lt;/em&gt; solution to your problems, but rather as one tool in your bioinformatics toolbox.  So, let’s get started!&lt;/p&gt;

&lt;h2 id=&quot;fire-up-your-cloud-computer&quot;&gt;Fire up your cloud computer&lt;/h2&gt;
&lt;p&gt;The two most popular cloud computing services are Amazon’s Web Services (AWS) and Google’s Cloud Platform.  Amazon, although the best known of the two, feels cumbersome to me – the first hour of the workshop and 36 slides were devoted just to getting our AWS instance up and running.  I prefer Google.  If you’re still undecided, I’d also point out that &lt;strong&gt;Google gives you a $300 credit&lt;/strong&gt;, good for 1 year from the time you activate your cloud account!  This is more than enough cash to work your way through this tutorial and still have plenty left for some of your own analyses.&lt;/p&gt;

&lt;p&gt;I put together the video tutorial below to walk you through the follow steps:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;setting up your Google Cloud compute instance&lt;/li&gt;
  &lt;li&gt;installing Docker on this instance&lt;/li&gt;
  &lt;li&gt;installing Chiron for quick and easy access to a bunch of dockerized programs for metagenomics&lt;/li&gt;
  &lt;li&gt;installing the Google Cloud SDK software &lt;em&gt;on your own computer&lt;/em&gt; (not the cloud) so you can easily connect to your new cloud resources&lt;/li&gt;
  &lt;li&gt;Connecting an FTP client to the instance so you can easily transfer files back and forth.&lt;/li&gt;
  &lt;li&gt;tearing it all down when you’re done&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below the video you’ll find all the commands to work through these steps on your own.&lt;/p&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/225609851&quot; width=&quot;500&quot; height=&quot;281&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;install-your-programs&quot;&gt;Install your programs&lt;/h2&gt;

&lt;p&gt;Once your gcloud instance is running, click on the ‘ssh’ button next to the instance to open a terminal window.  This fast and easy way to connect to your cloud instance is one nice feature of the way gcloud is setup. We’ll now use this ssh connection to install Docker and Chiron.&lt;/p&gt;

&lt;p&gt;Install Docker&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get install docker.io&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Install some dependencies that we’ll need for Chiron&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-key adv &lt;span class=&quot;nt&quot;&gt;--keyserver&lt;/span&gt; keyserver.ubuntu.com &lt;span class=&quot;nt&quot;&gt;--recv-keys&lt;/span&gt; 40976EAF437D05B5
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-key adv &lt;span class=&quot;nt&quot;&gt;--keyserver&lt;/span&gt; keyserver.ubuntu.com &lt;span class=&quot;nt&quot;&gt;--recv-keys&lt;/span&gt; F76221572C52609D
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt install &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; python3 python3-pip python-pip
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;pip3 install pyyaml requests
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;pip install pyyaml cwlref-runner&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Install &lt;a href=&quot;https://github.com/IGS/Chiron&quot;&gt;Chiron&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git clone https://github.com/IGS/Chiron.git&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Any docker images could be put on your instance at this point.  Take a look &lt;a href=&quot;http://biocontainers.pro/&quot;&gt;here&lt;/a&gt; to see if your favorite bioinformatics program has been dockerized&lt;/p&gt;

&lt;p&gt;Look around your working directory.  In particular, take note of all the cool metagenomics tools that are now available in /Chiron/bin&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;ls &lt;/span&gt;Chiron/bin&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Although the ssh terminal available right on your instance is very convenient, it does not establish a connection between our local computer and the cloud instance (which we must do in order to move files back and forth).  In order to do that, we’ll want to connect to our instance from the &lt;a href=&quot;https://en.wikipedia.org/wiki/Terminal_(macOS)&quot;&gt;terminal app&lt;/a&gt; on our local computer.  Go ahead and launch your Terminal app.  Before we do anything else, let’s execute a command in the terminal that will allow us to see hidden files in our directory.  We need access to a few of these hidden files for the purposes of this tutorial.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;defaults write com.apple.finder AppleShowAllFiles &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#then restart the finder to see these changes&lt;/span&gt;
killall Finder
&lt;span class=&quot;c&quot;&gt;#after this tutorial you can hide these files again by replacing 'true' with 'false'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now install the google SDK.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl https://sdk.cloud.google.com | bash&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;I my experience, if you encounter any issues with this entire tutorial, it will be with getting the SDK installed and connecting to your instance. For example, you may notice that the installation fails with the following error&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ERROR: Failed to fetch component listing from server. Check your network settings and try again&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This error has to do with the the IPv6 settings on your computer preventing you from being able to connect with a google server to download the SDK command line tools&lt;/p&gt;

&lt;p&gt;If you encounter this error, this fix is simple.  Begin by temporarily turning off IPv6 support for either Wi-Fi or Ethernet, depending on which one you are using to connect to the internet.  If you’re using a Wi-Fi connection, then you would turn-off with:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;networksetup &lt;span class=&quot;nt&quot;&gt;-setv6off&lt;/span&gt; Wi-Fi &lt;span class=&quot;c&quot;&gt;#if you're using ethernet, replace 'Wi-Fi' with 'Ethernet' in this line&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now reattempt the installation as you did above&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl https://sdk.cloud.google.com | bash&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Once you have Google Cloud SDK installed, &lt;em&gt;be sure to turn the IPv6 back on&lt;/em&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;networksetup &lt;span class=&quot;nt&quot;&gt;-setv6automatic&lt;/span&gt; Wi-Fi&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;connect-to-your-instance&quot;&gt;Connect to your instance&lt;/h2&gt;
&lt;p&gt;Now we’ll connect to the instance from within our Terminal.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;gcloud compute ssh instance-1 &lt;span class=&quot;c&quot;&gt;#if your instance is not called 'instance-1', be sure to modify this line accordingly&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Be patient here, as this may take a moment to connect.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If the above command failed with an authentication error, it’s because this is the first time you’ve run SDK and it isn’t sure that you should have access to your google account from the terminal.  Take a moment to authenticate&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;gcloud auth login
&lt;span class=&quot;c&quot;&gt;#this will open a browser window for you to select and sign-in to your google account&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#after doing this, return to your terminal window and you should be good to go&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#if this doesn't work, you may need to go though the gcloud initialization process by executing 'gcloud init'&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#either way, once you have authenticated your account you will need to reattempt connecting with 'gcloud compute ssh instance-1'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;launch-an-interactive-session-with-chiron&quot;&gt;Launch an interactive session with Chiron&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/IGS/Chiron&quot;&gt;Chiron&lt;/a&gt; gives you access to &lt;a href=&quot;https://qiime2.org/&quot;&gt;QIIME&lt;/a&gt; for processing marker gene sequence data, as well as the &lt;a href=&quot;https://bitbucket.org/biobakery/biobakery/wiki/browse/&quot;&gt;BioBakery suite&lt;/a&gt; of tools from &lt;a href=&quot;https://huttenhower.sph.harvard.edu/&quot;&gt;Curtis Huttenhower’s lab&lt;/a&gt; for handling shotgun metagenomic sequencing data.  One of the first steps in the BioBakery workflow is using &lt;a href=&quot;http://www.nature.com/nmeth/journal/v9/n8/full/nmeth.2066.html&quot;&gt;MetaPhlan2&lt;/a&gt; to get species and strain level composition information from raw sequence files.  This is a logical place for us to start as well.&lt;/p&gt;

&lt;p&gt;Launch the MetaPhlan2 interactive&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; ./Chiron/bin/phlan_interactive &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; ~/data
&lt;span class=&quot;c&quot;&gt;#the -l option tells the interactive to create a new folder in our home directory called 'data', and sets this folder as the default from which data will be read and to which outputs will be saved &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#This is where we'll put all our raw sequence data for analysis&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Set permissions so you can transfer data&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#check permissions on all files and folders in the directory&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; 
&lt;span class=&quot;c&quot;&gt;#make yourself owner of the 'data' folder&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;chown danielbeiting data &lt;span class=&quot;c&quot;&gt;#replace 'danielbeiting' with your username&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#set yourself as the group for the 'data' folder&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;chgrp danielbeiting data
&lt;span class=&quot;c&quot;&gt;#give yourself read/write/execute permission for the 'data' folder&lt;/span&gt;
chmod 777 data&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;rinse-and-repeat&quot;&gt;Rinse and repeat&lt;/h2&gt;
&lt;p&gt;Go through the steps below to make sure have mastered this tutorial:&lt;/p&gt;

&lt;p&gt;close your terminal, reopen, and make sure you can reconnect to your instance with&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;gcloud compute ssh instance-1&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;relaunch the interactive metaphlan session&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; ./Chiron/bin/phlan_interactive &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; ~/data &lt;span class=&quot;c&quot;&gt;#always be sure to use the '-l ~/data'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Go back to the your google cloud account, select the instance you’ve been working with (checkbox to the left of the instance), and choose ‘Delete’ from the menu bar.&lt;/p&gt;

&lt;p&gt;Make sure you can repeat the whole set-up again, &lt;em&gt;except&lt;/em&gt; for the installation of the SDK – this only needed to be done once.&lt;/p&gt;

&lt;p&gt;Once you’re comfortable with the whole process, you’re ready to move on to &lt;a href=&quot;http://hostmicrobe.org/microbiome/cloudComputing_part2/&quot;&gt;part II of this tutorial&lt;/a&gt;!&lt;/p&gt;


    &lt;p&gt;&lt;a href=&quot;http://localhost:4000/microbiome/cloudComputing_part1/&quot;&gt;Cloud computing for metagenomics - Part I&lt;/a&gt; was originally published by Beiting at &lt;a href=&quot;http://localhost:4000&quot;&gt;Home&lt;/a&gt; on July 14, 2017.&lt;/p&gt;
  </content>
</entry>

</feed>
